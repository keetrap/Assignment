{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "TRANXnVDO1KP",
      "metadata": {
        "id": "TRANXnVDO1KP"
      },
      "source": [
        "# Fine Tunning\n",
        "\n",
        "\n",
        "---\n",
        "**Model :** Stable-code-instruct-3b\n",
        "\n",
        "**Link :** [Stable 3B](https://huggingface.co/stabilityai/stable-code-instruct-3b)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf43fc1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:05:05.447128Z",
          "iopub.status.busy": "2024-08-09T13:05:05.446284Z",
          "iopub.status.idle": "2024-08-09T13:05:56.927608Z",
          "shell.execute_reply": "2024-08-09T13:05:56.926768Z"
        },
        "id": "cbf43fc1",
        "outputId": "b13358ab-d7f6-404d-e1d9-b5e2997c87ce",
        "papermill": {
          "duration": 51.491006,
          "end_time": "2024-08-09T13:05:56.930197",
          "exception": false,
          "start_time": "2024-08-09T13:05:05.439191",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-09 13:05:46.252318: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-09 13:05:46.252454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-09 13:05:46.386246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "!pip install -q peft\n",
        "!pip install -q bitsandbytes\n",
        "import pandas as pd\n",
        "import torch\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import LoraConfig, PeftModel\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "from peft import PeftModel, PeftConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10b9198",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:05:56.943301Z",
          "iopub.status.busy": "2024-08-09T13:05:56.942439Z",
          "iopub.status.idle": "2024-08-09T13:05:57.028071Z",
          "shell.execute_reply": "2024-08-09T13:05:57.027070Z"
        },
        "id": "f10b9198",
        "outputId": "46204085-0d98-48da-a2f4-906038f25ce9",
        "papermill": {
          "duration": 0.094282,
          "end_time": "2024-08-09T13:05:57.030382",
          "exception": false,
          "start_time": "2024-08-09T13:05:56.936100",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "hf_token = \"hf_yIIEeTomS-----------vEskXzlDffCF\"\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51284cc2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:05:57.059769Z",
          "iopub.status.busy": "2024-08-09T13:05:57.059255Z",
          "iopub.status.idle": "2024-08-09T13:05:57.123595Z",
          "shell.execute_reply": "2024-08-09T13:05:57.122574Z"
        },
        "id": "51284cc2",
        "papermill": {
          "duration": 0.072477,
          "end_time": "2024-08-09T13:05:57.125945",
          "exception": false,
          "start_time": "2024-08-09T13:05:57.053468",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7976e2c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:05:57.138022Z",
          "iopub.status.busy": "2024-08-09T13:05:57.137315Z",
          "iopub.status.idle": "2024-08-09T13:06:01.777721Z",
          "shell.execute_reply": "2024-08-09T13:06:01.776847Z"
        },
        "id": "a7976e2c",
        "outputId": "0e8a91d5-45b3-4061-eecf-ebc89116b978",
        "papermill": {
          "duration": 4.648634,
          "end_time": "2024-08-09T13:06:01.779967",
          "exception": false,
          "start_time": "2024-08-09T13:05:57.131333",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(\"/kaggle/input/dataset/final_data.csv\")\n",
        "df=df[:10000]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05da5b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:06:01.793778Z",
          "iopub.status.busy": "2024-08-09T13:06:01.792677Z",
          "iopub.status.idle": "2024-08-09T13:06:01.797360Z",
          "shell.execute_reply": "2024-08-09T13:06:01.796380Z"
        },
        "id": "a05da5b1",
        "papermill": {
          "duration": 0.013577,
          "end_time": "2024-08-09T13:06:01.799489",
          "exception": false,
          "start_time": "2024-08-09T13:06:01.785912",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_name='stabilityai/stable-code-instruct-3b'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92B-uzXdP5q0",
      "metadata": {
        "id": "92B-uzXdP5q0"
      },
      "source": [
        " * Load the tokenizer for the Stable Code Instruct model from the **stabilityai/stable-code-instruct-3b** repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52c5660",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ca28cb91999048b99a69ed16ef5637e6",
            "75e7f5626cb14c09b6916c982cd0878a",
            "d71dc1c26edf413a93277b84d18f3e60"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-09T13:06:01.812250Z",
          "iopub.status.busy": "2024-08-09T13:06:01.811691Z",
          "iopub.status.idle": "2024-08-09T13:06:02.513028Z",
          "shell.execute_reply": "2024-08-09T13:06:02.511880Z"
        },
        "id": "f52c5660",
        "outputId": "6f0a2015-4141-427f-b4a7-67cc25cf0d43",
        "papermill": {
          "duration": 0.71011,
          "end_time": "2024-08-09T13:06:02.515186",
          "exception": false,
          "start_time": "2024-08-09T13:06:01.805076",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca28cb91999048b99a69ed16ef5637e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/9.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75e7f5626cb14c09b6916c982cd0878a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d71dc1c26edf413a93277b84d18f3e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stable-code-instruct-3b\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b4f507",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:06:02.528767Z",
          "iopub.status.busy": "2024-08-09T13:06:02.528476Z",
          "iopub.status.idle": "2024-08-09T13:06:16.675768Z",
          "shell.execute_reply": "2024-08-09T13:06:16.674717Z"
        },
        "id": "79b4f507",
        "papermill": {
          "duration": 14.156801,
          "end_time": "2024-08-09T13:06:16.678178",
          "exception": false,
          "start_time": "2024-08-09T13:06:02.521377",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set the padding token to the end-of-sequence token (As per the model requirments from special_tokens_map.json file)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "pt_batch=tokenizer(df['text'].to_list(),\n",
        "                  padding=True,          # Pad sequences to the maximum length\n",
        "                  truncation=True,\n",
        "                  max_length=2048,\n",
        "                  return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fab07b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:06:16.691786Z",
          "iopub.status.busy": "2024-08-09T13:06:16.691462Z",
          "iopub.status.idle": "2024-08-09T13:06:16.697722Z",
          "shell.execute_reply": "2024-08-09T13:06:16.696780Z"
        },
        "id": "8fab07b1",
        "papermill": {
          "duration": 0.01536,
          "end_time": "2024-08-09T13:06:16.699665",
          "exception": false,
          "start_time": "2024-08-09T13:06:16.684305",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#DataLoader to iterate over the dataset in batches.\n",
        "#  Gpu does not permits batch size > 2\n",
        "tensor_dataset = TensorDataset(pt_batch['input_ids'], pt_batch['attention_mask'])\n",
        "dataloader = DataLoader(tensor_dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1abb8bec",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0f29481601c14d7fa80aa93ee62cb9c9",
            "2b4b30b7b0d9484eb90235cfaf9d4f51",
            "2f609b5d2fc7474480b56e4e20a3a4c7",
            "995f263d7a914477b21ff67f9baa03c6",
            "afa97d6e2c214d8f986506f28ca3dacb",
            "9776077814994bd3bcbdff3dd3580abb",
            "0ce7c7073356444b8728f5f3c0bf8676"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-09T13:06:16.712361Z",
          "iopub.status.busy": "2024-08-09T13:06:16.712085Z",
          "iopub.status.idle": "2024-08-09T13:07:00.991748Z",
          "shell.execute_reply": "2024-08-09T13:07:00.990870Z"
        },
        "id": "1abb8bec",
        "outputId": "acce08b2-b1f5-4371-e2b0-6bbed05879ad",
        "papermill": {
          "duration": 44.288928,
          "end_time": "2024-08-09T13:07:00.994378",
          "exception": false,
          "start_time": "2024-08-09T13:06:16.705450",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f29481601c14d7fa80aa93ee62cb9c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/738 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b4b30b7b0d9484eb90235cfaf9d4f51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/29.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f609b5d2fc7474480b56e4e20a3a4c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "995f263d7a914477b21ff67f9baa03c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afa97d6e2c214d8f986506f28ca3dacb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/610M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9776077814994bd3bcbdff3dd3580abb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ce7c7073356444b8728f5f3c0bf8676",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# BitsAndBytes for 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,               # loading the model in 4-bit\n",
        "    bnb_4bit_quant_type=\"nf4\",        # quantization  \"nf4\" for improved precision\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be5455d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:07:01.013111Z",
          "iopub.status.busy": "2024-08-09T13:07:01.012710Z",
          "iopub.status.idle": "2024-08-09T13:07:01.380604Z",
          "shell.execute_reply": "2024-08-09T13:07:01.379810Z"
        },
        "id": "6be5455d",
        "papermill": {
          "duration": 0.380483,
          "end_time": "2024-08-09T13:07:01.382940",
          "exception": false,
          "start_time": "2024-08-09T13:07:01.002457",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,    # task type as causal language modeling\n",
        "    inference_mode=False,\n",
        "    r=16,                             # low rank adaptation\n",
        "    lora_alpha=32,                     # alpha scaling factor\n",
        "    lora_dropout=0.1,\n",
        "    bias='none',\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]       # apply lora to query, key, value, output proj\n",
        ")\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)      # decay learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ac628f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:07:01.400078Z",
          "iopub.status.busy": "2024-08-09T13:07:01.399682Z",
          "iopub.status.idle": "2024-08-09T13:07:01.439162Z",
          "shell.execute_reply": "2024-08-09T13:07:01.437831Z"
        },
        "id": "89ac628f",
        "outputId": "3f4f3b31-c121-4a5a-c1e4-4280ffa7bef9",
        "papermill": {
          "duration": 0.050609,
          "end_time": "2024-08-09T13:07:01.441566",
          "exception": false,
          "start_time": "2024-08-09T13:07:01.390957",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): StableLmForCausalLM(\n",
              "      (model): StableLmModel(\n",
              "        (embed_tokens): Embedding(50304, 2560)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x StableLmDecoderLayer(\n",
              "            (self_attn): StableLmSdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "              (rotary_emb): StableLmRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): StableLmMLP(\n",
              "              (gate_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=2560, out_features=6912, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=6912, out_features=2560, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed529aa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T13:07:01.459463Z",
          "iopub.status.busy": "2024-08-09T13:07:01.459111Z",
          "iopub.status.idle": "2024-08-09T19:48:30.190507Z",
          "shell.execute_reply": "2024-08-09T19:48:30.189354Z"
        },
        "id": "3ed529aa",
        "outputId": "98691a05-5613-4f52-fa6e-65247f6a8084",
        "papermill": {
          "duration": 24088.743672,
          "end_time": "2024-08-09T19:48:30.193408",
          "exception": false,
          "start_time": "2024-08-09T13:07:01.449736",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1, Loss: 18.2879\n"
          ]
        }
      ],
      "source": [
        "# Running single epoch over 10000 rows of data due to memory and time constrains.\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for prompt_ids, code_ids in dataloader:\n",
        "        prompt_ids = prompt_ids.to(device)\n",
        "        code_ids = code_ids.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # reset gradients\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_ids=prompt_ids, labels=code_ids)\n",
        "        loss = output.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "model.save_pretrained('final_tune_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faa097a",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "26e8296089c2497584eed05a79fea0e2"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-08-09T19:48:30.213323Z",
          "iopub.status.busy": "2024-08-09T19:48:30.212391Z",
          "iopub.status.idle": "2024-08-09T19:48:33.202142Z",
          "shell.execute_reply": "2024-08-09T19:48:33.201037Z"
        },
        "id": "5faa097a",
        "outputId": "e5142ff2-e8c1-4215-978e-d09264e2a1c9",
        "papermill": {
          "duration": 3.002463,
          "end_time": "2024-08-09T19:48:33.204661",
          "exception": false,
          "start_time": "2024-08-09T19:48:30.202198",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26e8296089c2497584eed05a79fea0e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/keetrap/final_tune_model/commit/b9aa9f3406ab2245ddda946fcf8c00e70d04eb50', commit_message='Upload model', commit_description='', oid='b9aa9f3406ab2245ddda946fcf8c00e70d04eb50', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.push_to_hub('final_tune_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50480c7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T19:48:33.225732Z",
          "iopub.status.busy": "2024-08-09T19:48:33.225283Z",
          "iopub.status.idle": "2024-08-09T19:48:33.682007Z",
          "shell.execute_reply": "2024-08-09T19:48:33.681092Z"
        },
        "id": "50480c7c",
        "papermill": {
          "duration": 0.470514,
          "end_time": "2024-08-09T19:48:33.684562",
          "exception": false,
          "start_time": "2024-08-09T19:48:33.214048",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "peft_model_id = \"/kaggle/working/final_tune_model\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "# Loading the fine tuned model using the base model and the PEFT config.\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d7e851",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T19:48:33.704904Z",
          "iopub.status.busy": "2024-08-09T19:48:33.704524Z",
          "iopub.status.idle": "2024-08-09T19:48:33.721316Z",
          "shell.execute_reply": "2024-08-09T19:48:33.720546Z"
        },
        "id": "73d7e851",
        "papermill": {
          "duration": 0.029467,
          "end_time": "2024-08-09T19:48:33.723543",
          "exception": false,
          "start_time": "2024-08-09T19:48:33.694076",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Generate shopping website for Fashion Brand: A visually stunning layout with a full-width, rotating image carousel showcasing their latest collections, a bold, center-aligned logo, and a bottom navigation menu. The color palette is inspired by the latest fashion trends.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d9c9046",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T19:48:33.743907Z",
          "iopub.status.busy": "2024-08-09T19:48:33.743099Z",
          "iopub.status.idle": "2024-08-09T19:50:23.648928Z",
          "shell.execute_reply": "2024-08-09T19:50:23.647850Z"
        },
        "id": "1d9c9046",
        "outputId": "61a0863f-b468-4c94-8c3b-daef1b106b2e",
        "papermill": {
          "duration": 109.919047,
          "end_time": "2024-08-09T19:50:23.651826",
          "exception": false,
          "start_time": "2024-08-09T19:48:33.732779",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "tokens = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    top_k=100,\n",
        "    do_sample=True,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "output = tokenizer.batch_decode(tokens[:, inputs.input_ids.shape[-1]:], skip_special_tokens=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e671570f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-09T19:50:23.673616Z",
          "iopub.status.busy": "2024-08-09T19:50:23.672661Z",
          "iopub.status.idle": "2024-08-09T19:50:23.679046Z",
          "shell.execute_reply": "2024-08-09T19:50:23.677077Z"
        },
        "id": "e671570f",
        "outputId": "ecdb0239-1947-4da6-c70d-3affd2004c0b",
        "papermill": {
          "duration": 0.019759,
          "end_time": "2024-08-09T19:50:23.681670",
          "exception": false,
          "start_time": "2024-08-09T19:50:23.661911",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To generate a shopping website for a fashion brand with the described layout and features, we will use HTML, CSS, and JavaScript. We will also utilize a carousel library to handle the rotating image functionality.\n",
            "\n",
            "Here's an outline of the steps we'll follow:\n",
            "\n",
            "1. Create the HTML structure for the website, including the header, main content area, navigation menu, and footer.\n",
            "2. Style the website using CSS, incorporating a visually stunning layout, a full-width carousel, a bold logo, and a bottom navigation menu.\n",
            "3. Use JavaScript to handle the rotation functionality of the carousel.\n",
            "\n",
            "Let's start by creating the HTML structure.\n",
            "```html\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "  <meta charset=\"UTF-8\">\n",
            "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
            "  <title>Fashion Brand</title>\n",
            "  <link rel=\"stylesheet\" href=\"styles.css\">\n",
            "</head>\n",
            "<body>\n",
            "  <header>\n",
            "    <div class=\"logo\">\n",
            "      <img src=\"logo.png\" alt=\"Fashion Brand Logo\">\n",
            "    </div>\n",
            "  </header>\n",
            "  <main>\n",
            "    <div class=\"carousel\">\n",
            "      <!-- Carousel images will be inserted here -->\n",
            "    </div>\n",
            "    <nav>\n",
            "      <!-- Navigation menu will be inserted here -->\n",
            "    </nav>\n",
            "  </main>\n",
            "  <footer>\n",
            "    <!-- Footer content will be inserted here -->\n",
            "  </footer>\n",
            "\n",
            "  <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
            "  <script src=\"carousel.js\"></script>\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "Next, let's create a CSS file named \"styles.css\" to style the website.\n",
            "```css\n",
            "/* styles.css */\n",
            "\n",
            "body {\n",
            "  font-family: Arial, sans-serif;\n",
            "  margin: 0;\n",
            "  padding: 0;\n",
            "}\n",
            "\n",
            "header {\n",
            "  background-color: #f2f2f2;\n",
            "  padding: 20px;\n",
            "  text-align: center;\n",
            "}\n",
            "\n",
            ".logo img {\n",
            "  max-width: 100%;\n",
            "  height: auto;\n",
            "}\n",
            "\n",
            "main {\n",
            "  padding: 20px;\n",
            "}\n",
            "\n",
            ".carousel {\n",
            "  position: relative;\n",
            "  width: 100%;\n",
            "  height: 400px;\n",
            "  overflow: hidden;\n",
            "}\n",
            "\n",
            ".carousel img {\n",
            "  position: absolute;\n",
            "  top: 0;\n",
            "  left: 0;\n",
            "  width: 100%;\n",
            "  height: 100%;\n",
            "  opacity: 0;\n",
            "  transition: opacity 1s ease-in-out;\n",
            "}\n",
            "\n",
            ".carousel img.active {\n",
            "  opacity: 1;\n",
            "}\n",
            "\n",
            "nav {\n",
            "  background-color: #333;\n",
            "  color: #fff;\n",
            "  padding: 10px;\n",
            "  text-align: center;\n",
            "}\n",
            "\n",
            "nav a {\n",
            "  color: #fff;\n",
            "  text-decoration: none;\n",
            "  margin: 0 10px;\n",
            "}\n",
            "\n",
            "footer {\n",
            "  background-color: #f2f2f2;\n",
            "  padding: 20px;\n",
            "  text-align: center;\n",
            "}\n",
            "```\n",
            "\n",
            "Now, let's create a JavaScript file named \"carousel.js\" to handle the rotation functionality of the carousel.\n",
            "```javascript\n",
            "// carousel.js\n",
            "\n",
            "$(document).ready(function() {\n",
            "  const carouselImages = $('.carousel img');\n",
            "  const numImages = carouselImages.length;\n",
            "  let currentImageIndex = 0;\n",
            "\n",
            "  function showImage() {\n",
            "    carouselImages.eq(currentImageIndex).addClass('active');\n",
            "    currentImageIndex = (currentImageIndex + 1) % numImages;\n",
            "    setTimeout(showImage, 2000);\n",
            "  }\n",
            "\n",
            "  showImage();\n",
            "});\n",
            "```\n",
            "\n",
            "Finally, let's add the carousel images and navigation menu to the HTML file.\n",
            "```html\n",
            "<!-- Updated HTML structure -->\n",
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "  <meta charset=\"UTF-8\">\n",
            "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
            "  <title>Fashion Brand</title>\n",
            "  <link rel=\"stylesheet\" href=\"styles.css\">\n",
            "</head>\n",
            "<body>\n",
            "  <header>\n",
            "    <div class=\"logo\">\n",
            "      <img src=\"logo.png\" alt=\"Fashion Brand Logo\">\n",
            "    </div\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5520262,
          "sourceId": 9140253,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30747,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 24324.130842,
      "end_time": "2024-08-09T19:50:26.704229",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-08-09T13:05:02.573387",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
